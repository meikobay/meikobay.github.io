<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>2022年5月29日进城记</title>
    <url>/2022/05/29/2022%E5%B9%B45%E6%9C%8829%E6%97%A5%E8%BF%9B%E5%9F%8E%E8%AE%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote>
<p>时间：2022年5月28日</p>
<p>地点：杭州●西湖</p>
<p>人物：自己</p>
<p>天气：阵雨转多云</p>
<p>景点：潘天寿纪念馆、西湖博物馆、音乐喷泉至流浪闻莺段环湖绿道（约2公里）</p>
<p>交通：地铁5号线转地铁1号线</p>
<p>住宿：无</p>
</blockquote>
<p>从杭州西郊的老余杭要去所谓的杭州城（西湖附近）最便捷的出行方式是：从地铁5号线头一站（金星）乘坐到打铁关站，然后转地铁1号线至龙翔桥站，全程需要1个小时。这还没有计算从住处前往地铁站点的时间。所以，我平时很少去城里，更别提让我独自一人前往啦。</p>
<p>前几天，电子笔和耳机出了点问题，需要去一趟西湖旁边的售后进行检修。加上之前都是结伴来西湖，风景是大家的共同爱好，但是艺术不一定是，所以也就没有好好逛过西湖旁边的美术馆、博物馆什么的。于是，愉快的决定了这次进城之行。</p>
<p>中午1点到店里，已经过了预约的售后检修时间。工作人员让我重新预约一下。今天预约的人特别多，我能排到的最近时间是在下午5点，离现在还有四个小时。于是，我想着先去逛几个“馆”儿，时间应该正好。</p>
<span id="more"></span>

<h2 id="潘天寿纪念馆"><a href="#潘天寿纪念馆" class="headerlink" title="潘天寿纪念馆"></a>潘天寿纪念馆</h2><p>今天出门忘记带伞，天空下着小雨。抬眼望去就是西湖，烟雨朦胧，别有一番意境。我没沿着湖岸走，而是在地图上查到并导航去最近的是<strong>中国美术学院美术馆</strong>。到达目的地附近，满眼望去没找到美术馆，却看到一处类似农家庭院的建筑，不高的门庐边一块铜牌红底的写着<strong>潘天寿纪念馆</strong>。进馆后，我才知道潘天寿就是“中国画四大家”之一（其他三位：齐白石、黄宾虹、吴昌硕）。大画家，我只熟悉齐白石和黄宾虹，就这还得归功于我们的教材。</p>
<p>下图是纪念馆一楼入口处的对潘天寿与故居的介绍：</p>
<img src="https://tobyimgbed.oss-cn-hangzhou.aliyuncs.com/images/image-20220529234738595.png" alt="image-20220529234738595" style="zoom:67%;" />

<p>潘天寿纪念馆一楼和二楼展览了潘天寿的画作，也从这里详细了解了用手指作画这种方式。自古就有书画不分家一说，会作画的，一般书法都比较好，当然这个结论在当代是要打个折扣。最近刚听完林语堂的《苏东坡传》，北宋仁宗、英宗、神宗时期的著名书法家都是同时具有很高的书法与绘画成就。</p>
<p>每幅画旁边都有一幅对该画的解构说明。对画的解构有益于后来者学习技术，但是不益于作品本身。有时候，我们的一个“妙”、“好”、“赞”字背后的体验感是无穷尽的，而条理清楚的哪儿妙、哪儿好、哪儿赞反而将作品囿于高墙之内了。</p>
<p>里面很多画，好看的忘记拍照了。只有下面这两幅，欣赏欣赏：</p>
<img src="https://tobyimgbed.oss-cn-hangzhou.aliyuncs.com/images/image-20220529234818035.png" alt="image-20220529234818035" style="zoom: 50%;" />

<img src="https://tobyimgbed.oss-cn-hangzhou.aliyuncs.com/images/image-20220529234836413.png" alt="image-20220529234836413" style="zoom: 67%;" />



<p>馆内有介绍潘天寿论艺术的摘句，供自己时常学习，故引出如下：</p>
<p><img src="https://tobyimgbed.oss-cn-hangzhou.aliyuncs.com/images/IMG_4543.jpg" alt="IMG_4543"></p>
<h2 id="西湖博物馆"><a href="#西湖博物馆" class="headerlink" title="西湖博物馆"></a>西湖博物馆</h2><p>从潘天寿纪念馆出来后，继续找中国美术学院美术馆。这次仔细的跟着手机导航一步一步挪，到了一个不像美术馆的门口，还是抱着侥幸的心态问了保安大哥。保安大哥的回答又好气，又好笑，他回答到：你没看到在施工吗，你要进来干活吗？笑死，我是来欣赏艺术的，要干活还要跑这里来么？晕菜！</p>
<p>说实话，西湖边上的各种馆、古建筑太过密集了。当我作罢想返回苹果售后点时，打开地图发现100米处就是<strong>西湖博物馆</strong>。看一下时间，才3点，还有将近两个小时，不去白不去。哈哈，西湖周围的这些美术馆、博物馆都是免费对外开放的。</p>
<img src="https://tobyimgbed.oss-cn-hangzhou.aliyuncs.com/images/image-20220529161102479.png" alt="image-20220529161102479" style="zoom: 80%;" />



<p>这几个大字后面就是西湖博物馆了，而这块石头前面有一几个小孩在画画，旁边有几个像他们妈妈的人跟着，后来一问是画室的老师带着小孩们出来上课。</p>
<p>西湖博物馆大厅里是一个缩小版的西湖沙盘模型：</p>
<img src="https://tobyimgbed.oss-cn-hangzhou.aliyuncs.com/images/image-20220529235009382.png" alt="image-20220529235009382" style="zoom: 50%;" />

<p>展厅里介绍了西湖的历史，从唐代的白居易到宋朝的苏东坡和范仲淹，这些人都是直接与西湖相关的。然后，就是眠于西湖边的西湖三杰：岳飞、于谦、张苍水。里面还有介绍西湖的文化对朝鲜与日本文人精神和园林艺术的影响。</p>
<p>馆内还展示了西湖的动植物，从晚古生代的苔藓虫到第四世纪的牡蛎，再到更新民的水牛、野猪、中国犀、东方剑齿象等动物的牙齿化石。</p>
<p>下图是馆中的蝴蝶标本：</p>
<p><img src="https://tobyimgbed.oss-cn-hangzhou.aliyuncs.com/images/image-20220529235039370.png" alt="image-20220529235039370"></p>
<p>还有各种虫子的标本，从西湖中捞出的历朝历代的铜钱（看来西湖底下真有宝贝哦）。</p>
<p><img src="https://tobyimgbed.oss-cn-hangzhou.aliyuncs.com/images/image-20220529235129371.png" alt="image-20220529235129371"></p>
<p><img src="https://tobyimgbed.oss-cn-hangzhou.aliyuncs.com/images/image-20220529235148468.png" alt="image-20220529235148468"></p>
<h2 id="音乐喷泉至流浪闻莺段环湖绿道"><a href="#音乐喷泉至流浪闻莺段环湖绿道" class="headerlink" title="音乐喷泉至流浪闻莺段环湖绿道"></a>音乐喷泉至流浪闻莺段环湖绿道</h2><p>从西湖博物馆出来，时间到了四点多，该去售后点了。雨停了，我沿着西湖岸边往那售后点方向走。今天人还是挺多的，一路上有好看的人、有意思的事、好看的花草。例如，在接近音乐喷泉的岸边，有妈妈带着小男孩蹲着看湖中的野鸭子，湖中的鸭妈妈也带着小鸭子在近岸湖面游来游去。</p>
<p><img src="https://tobyimgbed.oss-cn-hangzhou.aliyuncs.com/images/IMG_4610.GIF" alt="IMG_4610"></p>
<p>还有一只很逗的青蛙，在荷叶上思考人生。</p>
<p><img src="https://tobyimgbed.oss-cn-hangzhou.aliyuncs.com/images/IMG_4613.GIF" alt="IMG_4613"></p>
<p>西湖及其周边的生态是真的好，在这里你可以看到人与自然和谐的一面。松鼠会与游客保持较近的距离，野鸭子也不怕人。都那么妙、好、赞！</p>
<p>有时候一个人出去走走也挺不错的，小小记录一下这次进城之行。</p>
]]></content>
      <categories>
        <category>日志</category>
        <category>游记</category>
      </categories>
      <tags>
        <tag>日志</tag>
        <tag>游记</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2022/05/25/hello-world/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<span id="more"></span>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
      <categories>
        <category>LifeRecord</category>
      </categories>
  </entry>
  <entry>
    <title>增量式学习介绍</title>
    <url>/2022/06/05/%E5%A2%9E%E9%87%8F%E5%BC%8F%E5%AD%A6%E4%B9%A0%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote>
<p>人工智能的参照样本始终没有离开我们人类自身。终身、增量式地学习能力是人类最重要的特点与能力之一。机器人如果能够像人类一样通过学习不断地适应新环境与新任务，便有可能实现通用人工智能。然而，本文要介绍的<strong>增量式学习</strong>原本就是领域老人为了实现类人学习而作的众多尝试之一。</p>
</blockquote>
<h2 id="一、基本定义"><a href="#一、基本定义" class="headerlink" title="一、基本定义"></a>一、基本定义</h2><p>抛除了类人学习这么大的帽子，增量式学习有它重要的现实意义：</p>
<p>1） 在现实世界中，数据一般是以序列的方式被机器人获取的，这些在线获取的数据包含新的知识需要被机器人学习。因此，机器人的学习系统能够从新获取的数据学习到新的知识。</p>
<p>2）对一个训练好的系统进行修改付出的代价通常低于重新训练一个系统。</p>
<p>增量式学习的思想可以描述为：每当新增数据时，并不需要重建知识库，而是在原有知识库的基础上，仅仅对由于新数据所带来的新信息对知识库进行增量式更新。这种增量式学习的方式使得机器人更加接近人类。现有的增量式学习框架有很多，各种框架的核心内容是：<strong>研究更有效的评价新数据与已存储知识相似性的方法。</strong></p>
<p>相似性评价方法决定了觉察新知识与增长知识库的方式，它作为新知识的判定机制是增量式学习的核心部件。下面小节会针对几种常见的增量式学习框架进行介绍，主要包括<strong>自组织增量式学习神经网络</strong>(<a href="https://cs.nju.edu.cn/rinc/Soinn.html">SOINN</a>)[^1]、<strong>情景记忆马尔可规决策过程</strong>(<a href="https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CDFD&dbname=CDFDLAST2015&filename=1015572048.nh&uniplatform=NZKPT&v=g8C05oKV3JGiAK2N666FSFqzwyd_UkYomE96OV4kHsGr4R8XbWpFZ-aeNg1e3UUS">EM-MDP</a>)[^2]、<strong>增量式分级判别回归树</strong>(<a href="https://ieeexplore.ieee.org/document/4118285">IHDR</a>)[^3]。</p>
<span id="more"></span>

<h2 id="二、自组织增量式学习神经网络-SOINN"><a href="#二、自组织增量式学习神经网络-SOINN" class="headerlink" title="二、自组织增量式学习神经网络-SOINN"></a>二、自组织增量式学习神经网络-SOINN</h2><p>自组织增量学习神经网络SOINN是一种基于竞争学习的两层神经网络。SOINN的增量性使得它能够发现数据流中出现的新模式并进行学习，同时不影响之前学习的结果。因此SOINN能够作为一种通用的学习算法应用于各类非监督学习问题中。<br>SOINN是两层结构（不包括输入层）的竞争性神经网络，它以自组织的方式对输入数据进行在线聚类和拓扑表示，其工作过程如图1所示。</p>
<img src="https://tobyimgbed.oss-cn-hangzhou.aliyuncs.com/images/202206052216842.png" alt="img" style="zoom:50%;" />



<ul>
<li><p>第1层网络接受原始数据的输入，以在线的方式自适应地生成原型神经元来表示输入数据。这些由原型神经元表示的节点和其他节点之间的连接反映了原始数据的分布情况； </p>
</li>
<li><p>第2层根据第1层网络的结果估计出原始数据的类间距离与类内距离，并以此作为参数，把第1层生成的神经元作为输入再运行一次SOINN算法，以稳定学习结果。</p>
</li>
</ul>
<p>如图2所示：当输入数据存在多个聚类并存在噪声时，SOINN依然能够生成可靠的神经元节点来表示输入数据中的各个聚类；同时子图的拓扑结构反映了原始数据分布的性。</p>
<img src="https://tobyimgbed.oss-cn-hangzhou.aliyuncs.com/images/202206052216087.png" alt="img" style="zoom:50%;" />



<p>动态调整是SOINN实现自组织和增量学习的关键，它使得神经元的权值向量和网络的拓扑结构能够随着输入模式的到来动态地进行调整，以优化对输入数据的表达精度。此外，通过适时增加神经元不仅能够自适应地确定神经元的数量以满足一定的量化误差约束，同时还能在不影响之前学习结果的情况下适应之前没有学习过的输入模式。SOINN分别定义了类内节点插入和类间节点插入操作来达到这两个目的。 </p>
<ul>
<li><pre><code>类内的节点插入操作主要是为了自适应地减小神经元的量化误差,尽可能准确地近似原始数据的分布.具体的,SOINN 在运行过程中会记录每个神经元的累积量化误差,每学习一段固定的时间之后,找出所有节点中累积量化误差最大的两个节点,然后在它们的中间插入一个新的节点,以插值的方式更新它们的累计量化误差值.考虑到并非每次插入操作都是有必要的,如果不进行一些限制的话,那么随着算法的进行,节点的数量会不断地增加.因此,SOINN 在每次类内的节点插入操作后都会再判断该次插入操作是否显著降低了量化误差:如果没有,则取消本次插入操作。
</code></pre>
</li>
<li><p>类间节点插入发生在新输入的数据与之前学习过的数据差异性较大的时候.SOINN 通过为每一个神经元i设置一个相似度阈值(similarity threshold)参数$T_i$来判断新来的数据样本是否有可能属于一个新的类别:如果该数据点与之前学习得到神经元差异性较大,就在该数据点的位置上生成一个新的节点来代表这个可能的模式.如图3 所示,ξ为新输入的数据点,SOINN 首先找到与其最相似的两个神经元$s_1$ 与$s_2$,如果$d(s_1,ξ)&gt;T_(s_1 )$或者 $d(s_2,ξ)&gt;T_(s_2 )$,就认为数据点ξ的差异性较大.其中,$d(∙)$为相似度度量函数(通常为欧氏距离函数).新生成的节点并不意味着最终一定属于一个新的聚类,只是在当前的相似度阈值下,该输入与之前学习到的模式存在较大差异.随着越来越多的输入模式得到学习，相似度阈值和神经元之间的连接也在不断变化。</p>
</li>
</ul>
<img src="https://tobyimgbed.oss-cn-hangzhou.aliyuncs.com/images/202206052234396.png" alt="image-20220605223410687" style="zoom:33%;" />

<center>图3   类间节点插入示意图</center>

<p>可以看出:类间节点插入是SOINN 实现增量学习的关键,节点插入的时机对于最终的结果有较大影响,而每个节点的相似度阈值参数$T$ 又是决定插入操作的关键.如果$T$值过小,则每个数据都会被认为是一个新的模式而生成一个节点;$T$ 值过大,则会导致节点个数过少,此时量化误差增大,而且不能准确反映数据的分布.理想情况下,该参数应大于平均的类内距离同时小于平均的类间距离。SOINN在这个问题上采用了一种自适应的方式不断更新$T_i $ 的值，使得能够适应不断变化的输入模式。</p>
<p>假设$N$为所有节点的集合，$N_i$为节点i的邻居节点集合。如果$N_i$不为空，即，存在其他节点通过一条边与其相连，就令：</p>
<p>$$T_i&#x3D;max_{j \in N_i}||W_i-W_j||$$</p>
<p>否则，$T_i&#x3D;min_{j \in N \setminus {i}}||W_i-W_j||$。</p>
<p>可以看出，这两个定义实际上是当前对最大类内距离和最小类间距离的估计值。实际应用表明，这样的动态调整方法是行之有效的。</p>
<h2 id="三、情景记忆马尔可规决策过程-EM-MDP"><a href="#三、情景记忆马尔可规决策过程-EM-MDP" class="headerlink" title="三、情景记忆马尔可规决策过程-EM-MDP"></a>三、情景记忆马尔可规决策过程-EM-MDP</h2><p>情景记忆马尔可夫决策过程EM-MDP准确来说是一套完整的人工智能方案（简化版），这个框架中包括对情景的认知、增量式学习、短期与长期记忆模型。我们将焦点放在框架中的增量式学习部分。该框架基于自适应共振理论（<a href="https://blog.csdn.net/u013468614/article/details/94751690?spm=1001.2014.3001.5501">ART</a>）与稀疏分布记忆（SDM）的思想实现对情景记忆序列的增量式学习。</p>
<p>SDM是计算机科学家彭蒂.卡内尔瓦于1974年提出的能够将思维所拥有的任何感知存入有限记忆机制的方法。在学习过程中，每次可有多个状态神经元同时被激活，每个神经元均可看成一类相近感知的代表。相比SOINN网络（每次最多只能有一个输出节点），该方法具有环境适应性好的优点。<br>情景记忆网络学习模型的构建基于EM-MDP模型框架，由感知输入（O层）、感知相似性度量（U层）、状态神经元（S层）和输出情景记忆（E层）组成，其结构模型如图4所示。</p>
<img src="https://tobyimgbed.oss-cn-hangzhou.aliyuncs.com/images/202206052251635.png" alt="img" style="zoom:67%;" />

<center>图4   EM-MDP模型框架。</center>

<p>框架中U层与S层都具有增量式学习的能力，U层与S层的结构如图5所示。U层节点个数等于输入感知的维数，每个节点的输出由3个信号共同确定：（1）当前环境的感知输入$o_c$;（2）控制信号$C1$；（3）由S层反馈的获胜状态神经元的映射感知。</p>
<img src="https://tobyimgbed.oss-cn-hangzhou.aliyuncs.com/images/202206052253913.png" alt="img" style="zoom: 67%;" />

<center>图5   网络U层与S层的结构。左：U层；右：S层。</center>

<p>U层节点的输出u根层这3个信号采用“多数表决2&#x2F;3”原则计算获得。当$C1&#x3D;1$，反馈映射感知信号为0时，U层节点输出由输入感知决定，即$u&#x3D;o_c$。当反馈映射感知信号不为0，$C1&#x3D;0$时，U层节点输出取决于输入感知与反馈映射感知的比较情况，如果相似性度量大于阈值，则对感知向量学习进行调整，否则增加新的感知$o_{m+1}&#x3D;o_c$。S层有m个节点，用以表示m个状态神经元，该状态神经元空间可通过增加新的神经元节点进行动态增长。状态神经元间具有权值，代表情景记忆的连接关系。</p>
<p>情景网络接受来自环境的感知输入，通过检查当前感知输入与所有存储感知向量之间的匹配程度，确定新感知及其相关事件是否已存在机器人的情景记忆当中。按照预先设定的激活阈值来考察相似性度量，决定对新输入的感知采取何种处理方式。在网络每一次接受新的感知输入时，都需要经过一次匹配过程。相似性度量存在两种情况：</p>
<ul>
<li><pre><code>**相似度超过设定阈值**，则选择该邻近状态集为当前输入感知的代表状态神经元集合。感知通过学习进行调整以使其之后遇到与当前输入感知接近的感知时能获得更大的相似度，对非该邻近状态集，感知向量不做任何调整。**实际上是对情景记忆中的映射感知进行重新编码，以稳定已经被学习了的熟悉事件。**
</code></pre>
</li>
<li><pre><code>**相似度不超过设定阈值**，需要在S层新增一个代表新输入感知的状态神经元并存储当前感知为该新增状态的映射感知，以便参加之后的匹配过程。同时建立与该状态神经元相连的权值，以存储该类感知和参与以后的匹配过程。**实际上是对不熟悉事件建立新的表达编码。**
</code></pre>
</li>
</ul>
<h2 id="三、增量式分级判别回归树-IHDR"><a href="#三、增量式分级判别回归树-IHDR" class="headerlink" title="三、增量式分级判别回归树-IHDR"></a>三、增量式分级判别回归树-IHDR</h2><p>上文介绍的SOINN与EM-MDP都是初始应用于都是无标签数据，其中SOINN也被拓展至机器人导航任务中，是一个典型的带标签数据（$x\rightarrow y$）学习问题。然而，增量式分级判别回归树（IHDR）就面向$x\rightarrow y$任务设计的。相似的是，IHDR也是一个自组织的聚类过程，只不过IHDR的聚类是一种同时考虑了输入空间X与输出空间Y的信息<strong>双聚类</strong>。</p>
<p>IHDR的每一个内部节点都增量式的维护y-clusters和x-clusters。如图6所示，对于每个节点的每一个类别最多能分成q类(q是一个设定的最大值).</p>
<p><img src="https://tobyimgbed.oss-cn-hangzhou.aliyuncs.com/images/202206052316399.png" alt="在这里插入图片描述"></p>
<center>图6   X-Y空间双聚类。</center>

<p>数学上的描述为，输入空间$X$的聚类是以输出空间$Y$作为条件的。所以，对于每一个x-cluster，都是随机变量$x\in X$关于随机变量$y\in Y$的条件概率分布，记为$p(x|Y\in c_i)$，其中$c_i$是第$i$个y-cluster，$i-&#x3D;1,2,…,q$。</p>
<p>$q$个y-clusters基于$y$确定了每一个到来样本$(x,y)$的虚拟标签。虚拟标签被用来确定对于当前的$(x,y)$，应该利用它的$x$对哪一个x-cluster进行更新。每一个x-cluster近似在$X$空间中与之相关的样本总体。如果需要一个更加精细的近似，它可能会产生一个子节点。</p>
<p>同时考虑X与Y的双聚类具有<strong>自适应局部准（quasi）不变性</strong>，如图7（a）所示，输入对应四种输出，用不同的符号表示。但是如果不考虑输出的信息，那么这些状态就程现出一团糟。看不到明显的规律。而图7（b）中，因为考虑了输出的信息，所以能够更合理的将这些样本分开。</p>
<p><img src="https://tobyimgbed.oss-cn-hangzhou.aliyuncs.com/images/202206052326347.png" alt="img"></p>
<center>图7   双聚类的自适应局部准不变性示例。</center>

<p>如下图所示为一个IHDR树。每一个节点都类似一个皮质区域。状态空间$X$是由d维的向量表示，它最初被粗糙的分成4份。每个部分都是根节点的子节点。每个子节点都具有它自己的小区域。这样从粗到精的划分，将输入空间逐渐划分成很小的区域。如果一个子结点接收到足够多的样本，它将又划分成q个子节点。在叶子结点中，micro-clusters以$(x_i, y_i)$的形式存在。</p>
<p>如果$x$给定，但是$y$未知，我们可以通过搜索IHDR树直到叶子节点，从而获取对应输出值作为当前状态的预测。</p>
<p><img src="https://tobyimgbed.oss-cn-hangzhou.aliyuncs.com/images/202206052329113.png" alt="img"></p>
<center>图8   IHDR示意图。</center>

<p>更多IHDR细节请参阅IHDR文献（本人在博客上也给出<a href="https://blog.csdn.net/u013468614/article/details/100880161?spm=1001.2014.3001.5501">IHDR的译文</a>）。</p>
<h2 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h2><p>通过查阅相关文献，SOINN被应用的相对较多。有用来对环境进行增量式构建路图，也有以处理过的视觉信息作为特征输入进行认知地图构建的。而EM-MDP结还未对其中增量式学习部分进行有效的框架分离，所以结构相对作为单独框架提出来的SOINN不是很清晰。IHDR也被应用于地面移动机器人与飞行机器人的导航任务中。</p>
<p>增量式学习的核心部件是对新旧知识的处理上，而将一个输入判定是否为新知识，则需要度量新输入与旧知识之间的“距离”。对知识网络中的噪声进行过滤处理也是维护一个有效知识网络的必不可少的部分。<strong>最后值得注意的是，SOINN的评判阈值是自动动态调整的，而EM-MDP中的阈值是预先设定的一个定值。SOINN、EM-MDP以及IHDR的学习过程的核心部件都是聚类，其中IHDR的聚类是一个考虑输入-输出的双聚类。</strong></p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[^1]: Shen F, Hasegawa O. An incremental network for on-line unsupervised classification and topology learning[J]. Neural Networks, 2006, 19 (1) :90–106. [<a href="http://dx.doi.org/10.1016/j.neunet.2005.04.006">doi:10.1016&#x2F;j.neunet.2005.04.006]</a><br>[^2]: 刘冬. 基于情景记忆的机器人认知行为学习与控制方法[D].大连理工大学,2014.<br>[^3]: Weng J and Hwang W. Incremental Hierarchical Discriminant Regression[J]. <em>IEEE Transactions on Neural Networks</em>, 2007, 18(2): 397-415, <a href="https://doi.org/10.1109/TNN.2006.889942">[doi: 10.1109&#x2F;TNN.2006.889942]</a>  </p>
]]></content>
      <categories>
        <category>类人学习</category>
        <category>机器人学习</category>
      </categories>
      <tags>
        <tag>Continuous Learning</tag>
        <tag>Lifelong Learning</tag>
        <tag>Incremental Learning</tag>
      </tags>
  </entry>
</search>
